#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
driver_business_quickstats_mix_v2.py
---------------------------------
èåˆåŸå­—æ®µ+æ­£åˆ™+LLMç»“æ„åŒ–ï¼Œä¸šåŠ¡ç±»å‹æ ‡å‡†åŒ–å½’å¹¶ï¼Œå¤šç»´åº¦ç»Ÿè®¡ï¼Œè‡ªåŠ¨ç¾åŒ–Excelã€‚
"""
import os
import re
import sys
from pathlib import Path
from dotenv import load_dotenv
import pandas as pd
import openai
from openpyxl import load_workbook
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.utils import get_column_letter
import logging

# â€”â€”â€” æ—¥å¿—é…ç½® â€”â€”â€”
logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s %(levelname)s %(message)s",
                    datefmt="%Y-%m-%d %H:%M:%S",
                    handlers=[logging.StreamHandler(sys.stderr)])

# â€”â€”â€” ç¯å¢ƒä¸Key â€”â€”â€”
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
logging.info(f"Using API Key: {openai.api_key}")

# â€”â€”â€” è·¯å¾„é…ç½® â€”â€”â€”
BASE_DIR = Path(r"E:\kabuda_data_analysis\å¸æœºä¸šåŠ¡ä¿¡æ¯åº“")
CSV = BASE_DIR / "å¸æœºä¸šåŠ¡.csv"
XLSX = BASE_DIR / "å¸æœºä¸šåŠ¡.xlsx"
XLSX_OUT = BASE_DIR / "å¸æœºä¸šåŠ¡_ç»Ÿè®¡åˆ†æ.xlsx"
MODEL = "gpt-3.5-turbo"

# â€”â€”â€” 1. è¯»å–æ•°æ® â€”â€”â€”
if CSV.exists():
    df = pd.read_csv(CSV, dtype=str)
elif XLSX.exists():
    df = pd.read_excel(XLSX, sheet_name=0, dtype=str)
else:
    raise FileNotFoundError("æœªæ‰¾åˆ°å¸æœºä¸šåŠ¡.csvæˆ–å¸æœºä¸šåŠ¡.xlsx")
df = df.fillna("")  # é˜²æ­¢ç©ºå€¼æŠ¥é”™
logging.info(f"è¯»å–æ•°æ®ï¼Œè¡Œæ•°: {len(df)}")

# â€”â€”â€” 2. ç»“æ„åŒ–æå–â€œè®¢å•æ¦‚è¿°â€ä¸»è¦å­—æ®µ â€”â€”â€”
def extract_info(text):
    logging.info(f"[Regex] Processing text: {text}")
    # ä¸šåŠ¡ç±»å‹
    if re.search(r"æ¥æœº|é€æœº", text):
        type_ = "æ¥é€æœº"
    elif re.search(r"åŒ…è½¦|ä¸€æ—¥æ¸¸|å¤šæ—¥æ¸¸|åŒ…æ—¥", text):
        type_ = "åŒ…è½¦"
    elif re.search(r"è·‘è…¿|ä»£ä¹°|ä»£å–|ä»£é€|ä»£è´­", text):
        type_ = "è·‘è…¿"
    elif re.search(r"è¡Œæå¯„å­˜|å¯„å­˜", text):
        type_ = "è¡Œæå¯„å­˜"
    elif re.search(r"æ¬å®¶|æ¬è¿", text):
        type_ = "æ¬å®¶"
    elif re.search(r"ç”µè¯|å«é†’|å«äºº", text):
        type_ = "ä»£åŠ/å…¶å®ƒ"
    else:
        type_ = ""
    # åŒºåŸŸåˆ¤å®š
    area_match = re.search(
        r"å¤šä¼¦å¤š|Toronto|çš®å°”é€Š|Markham|Richmond Hill|ä¸‡é”¦|Scarborough|å£«å˜‰å ¡|çº¦å…‹|North York|Etobicoke|å¯†è¥¿æ²™åŠ |Mississauga|æœºåœº",
        text, re.I)
    area_ = area_match.group(0) if area_match else ""
    # é‡‘é¢
    amount_match = re.search(r"[ğŸ’°\$](\d+(\.\d+)?)", text)
    amount = amount_match.group(1) if amount_match else ""
    # èµ·ç‚¹ç»ˆç‚¹
    addresses = re.findall(
        r"ä»\s*([\u4e00-\u9fa5a-zA-Z0-9 ,#\-]+?)(?:åˆ°|â€”|-|ï¼|â€”â€”)\s*([\u4e00-\u9fa5a-zA-Z0-9 ,#\-]+)",
        text)
    if addresses:
        start, end = addresses[0]
    else:
        start, end = "", ""
    # æ—¶é—´
    time_match = re.search(
        r"(\d{1,2}[:ï¼š]\d{2}\s*(?:AM|PM|am|pm)?)|(\d{1,2}ç‚¹åŠ?)|(\d{1,2}/\d{1,2}\s*\d{1,2}[:ï¼š]\d{2})|(?:ä¸Šåˆ|ä¸‹åˆ|ä¸­åˆ)\s*\d{1,2}[:ï¼š]?\d{0,2}",
        text)
    time_ = time_match.group(0) if time_match else ""
    logging.info(f"[Regex] Result -> type:{type_}, area:{area_}, amount:{amount}, start:{start}, end:{end}, time:{time_}")
    return {
        "ä¸šåŠ¡ç±»å‹_struct": type_,
        "åŒºåŸŸ_struct": area_,
        "é‡‘é¢_struct": amount,
        "èµ·ç‚¹": start,
        "ç»ˆç‚¹": end,
        "æ—¶é—´_struct": time_
    }

extract_results = df["è®¢å•æ¦‚è¿°"].apply(extract_info).apply(pd.Series)

# â€”â€”â€” åªå¯¹æ­£åˆ™æ²¡å‘½ä¸­çš„éƒ¨åˆ†ï¼Œç”¨LLMè¡¥é½ â€”â€”â€”
to_llm_idx = extract_results[(extract_results["ä¸šåŠ¡ç±»å‹_struct"] == "") |
                             (extract_results["åŒºåŸŸ_struct"] == "")].index
llm_targets = df.loc[to_llm_idx, "è®¢å•æ¦‚è¿°"].tolist()
logging.info(f"Need LLMè¡¥å…¨çš„è¡Œæ•°: {len(to_llm_idx)}")

def llm_extract(batch):
    logging.info(f"[LLM] Processing batch of size {len(batch)}")
    prompt = (
        "ä½ æ˜¯ä¸šåŠ¡å½’ç±»åŠ©æ‰‹ï¼Œè¯·ä»…è¾“å‡ºå¦‚ä¸‹æ ¼å¼ï¼š\n"
        "ä¸šåŠ¡ç±»å‹: <ç±»å‹>\nåŒºåŸŸ: <åŒºåŸŸ>\n"
        "åªå…è®¸è¿”å›ä¸¤è¡Œï¼Œä¸åŠ å…¶å®ƒæ–‡å­—ã€‚"
    )
    out = []
    for text in batch:
        logging.info(f"[LLM] Input text: {text}")
        try:
            resp = openai.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": text},
                ],
                temperature=0.0,
                max_tokens=30,
            )
            ans = resp.choices[0].message.content.strip()
            logging.info(f"[LLM] Output: {ans}")
            t = re.search(r"ä¸šåŠ¡ç±»å‹[:ï¼š]\s*(\S+)", ans)
            a = re.search(r"åŒºåŸŸ[:ï¼š]\s*(\S+)", ans)
            out.append({
                "ä¸šåŠ¡ç±»å‹_struct": t.group(1) if t else "",
                "åŒºåŸŸ_struct": a.group(1) if a else ""
            })
        except Exception as e:
            logging.error(f"[LLM] call failed: {e}")
            out.append({"ä¸šåŠ¡ç±»å‹_struct": "", "åŒºåŸŸ_struct": ""})
    return pd.DataFrame(out)

if llm_targets:
    batches = [llm_targets[i:i+10] for i in range(0, len(llm_targets), 10)]
    llm_out = pd.concat([llm_extract(b) for b in batches], ignore_index=True)
    extract_results.loc[to_llm_idx, ["ä¸šåŠ¡ç±»å‹_struct", "åŒºåŸŸ_struct"]] = llm_out.values

# â€”â€”â€” åˆå¹¶åˆ°åŸdf â€”â€”â€”
for col in extract_results.columns:
    df[col] = extract_results[col]
logging.info("å­—æ®µåˆå¹¶å®Œæ¯•ã€‚")

# ========== å­—æ®µèåˆ ==========
df["ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–"] = df["ä¸šåŠ¡ç±»å‹_struct"]
if "è®¢å•ç±»å‹" in df.columns:
    df.loc[df["ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–"] == "", "ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–"] = df["è®¢å•ç±»å‹"]
# å¤§ç±»å–è®¢å•ç±»å‹
df["ä¸šåŠ¡ç±»å‹_å¤§ç±»"] = df.get("è®¢å•ç±»å‹", "")
logging.info("å­—æ®µèåˆå®Œæ¯•ã€‚")

# ========== ç»Ÿè®¡åˆ†æSheetç”Ÿæˆ ==========

def try_to_float(x):
    try:
        return float(x)
    except:
        return None

report_tables = {}

# 1. ä¸šåŠ¡ç±»å‹åˆ†å¸ƒ_ç»†åˆ†
vc = df["ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–"].value_counts(dropna=False).reset_index()
vc.columns = ["ä¸šåŠ¡ç±»å‹_ç»†åˆ†", "æ•°é‡"]
report_tables["ä¸šåŠ¡ç±»å‹åˆ†å¸ƒ_ç»†åˆ†"] = vc

# 2. ä¸šåŠ¡ç±»å‹åˆ†å¸ƒ
vc = df["ä¸šåŠ¡ç±»å‹_å¤§ç±»"].value_counts(dropna=False).reset_index()
vc.columns = ["ä¸šåŠ¡ç±»å‹", "æ•°é‡"]
report_tables["ä¸šåŠ¡ç±»å‹åˆ†å¸ƒ"] = vc

# 3. åŒºåŸŸåˆ†å¸ƒ
if "åŒºåŸŸ_struct" in df.columns:
    vc = df["åŒºåŸŸ_struct"].value_counts(dropna=False).reset_index()
    vc.columns = ["åŒºåŸŸ_struct", "æ•°é‡"]
    report_tables["åŒºåŸŸåˆ†å¸ƒ"] = vc

# 4. é‡‘é¢åŒºé—´åˆ†å¸ƒ
for col in ["é‡‘é¢_struct", "è®¢å•é‡‘é¢", "é‡‘é¢"]:
    if col in df.columns:
        amount = df[col].apply(try_to_float)
        bins = [0, 50, 100, 200, 500, 1000, float('inf')]
        labels = ["0-50", "50-100", "100-200", "200-500", "500-1000", "1000+"]
        cut = pd.cut(amount, bins=bins, labels=labels, right=False)
        vc = cut.value_counts(sort=False).reset_index()
        vc.columns = ["åŒºé—´", "æ•°é‡"]
        report_tables["é‡‘é¢åŒºé—´åˆ†å¸ƒ"] = vc
        break

# 5. è®¢å•çŠ¶æ€åˆ†å¸ƒ
for col in ["è®¢å•çŠ¶æ€"]:
    if col in df.columns:
        vc = df[col].value_counts(dropna=False).reset_index()
        vc.columns = [col, "æ•°é‡"]
        report_tables["è®¢å•çŠ¶æ€åˆ†å¸ƒ"] = vc
        break

# 6. è¯„åˆ†åŒºé—´åˆ†å¸ƒ
for col in ["è¯„åˆ†", "å®¢æˆ·è¯„åˆ†"]:
    if col in df.columns:
        score = df[col].apply(try_to_float)
        bins = [0, 3, 5, 8, 10]
        labels = ["0-3", "3-5", "5-8", "8-10"]
        cut = pd.cut(score, bins=bins, labels=labels, right=False, include_lowest=True)
        vc = cut.value_counts(sort=False).reset_index()
        vc.columns = ["åŒºé—´", "æ•°é‡"]
        report_tables["è¯„åˆ†åŒºé—´åˆ†å¸ƒ"] = vc
        break

# 7. è¿Ÿåˆ°åˆ†å¸ƒ
for col in ["æ˜¯å¦è¿Ÿåˆ°", "è¿Ÿåˆ°", "è¿Ÿåˆ°æ¬¡æ•°"]:
    if col in df.columns:
        vc = df[col].value_counts(dropna=False).reset_index()
        vc.columns = [col, "æ•°é‡"]
        report_tables["è¿Ÿåˆ°åˆ†å¸ƒ"] = vc
        break

# 8. æŒ‰æœˆè¶‹åŠ¿
for col in ["ä¸‹å•æ—¶é—´", "è®¢å•æ—¥æœŸ", "åˆ›å»ºæ—¶é—´"]:
    if col in df.columns:
        dates = pd.to_datetime(df[col], errors="coerce")
        monthly = dates.dt.to_period("M").value_counts().sort_index().reset_index()
        monthly.columns = ["æœˆä»½", "è®¢å•æ•°"]
        report_tables["æ¯æœˆè®¢å•è¶‹åŠ¿"] = monthly
        break

# 9. å¸æœºåˆ†å¸ƒ
for col in ["å¸æœº", "å¸æœºå§“å", "å¸æœºID"]:
    if col in df.columns:
        vc = df[col].value_counts(dropna=False).reset_index()
        vc.columns = [col, "æ•°é‡"]
        report_tables["å¸æœºåˆ†å¸ƒ"] = vc
        break

# 10. èµ·ç‚¹ç»ˆç‚¹æµå‘åˆ†æ
if "èµ·ç‚¹" in df.columns and "ç»ˆç‚¹" in df.columns:
    flow = df.groupby(["èµ·ç‚¹", "ç»ˆç‚¹"]).size().reset_index(name="è®¢å•æ•°").sort_values("è®¢å•æ•°", ascending=False)
    report_tables["æµå‘ç»Ÿè®¡"] = flow

# 11. ä¸šåŠ¡ç±»å‹å¯¹æ¯” (å§‹ç»ˆç”Ÿæˆï¼Œå¦‚æœæ— å·®å¼‚åˆ™ä¸ºç©ºè¡¨)
if "è®¢å•ç±»å‹" in df.columns:
    diff_mask = (df["è®¢å•ç±»å‹"] != df["ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–"]) & (df["ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–"] != "")
    df_diff = df.loc[diff_mask, ["è®¢å•æ¦‚è¿°", "ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–", "ä¸šåŠ¡ç±»å‹_å¤§ç±»"]].rename(
        columns={"ä¸šåŠ¡ç±»å‹_ç»“æ„åŒ–": "ç»“æ„åŒ–ä¸šåŠ¡ç±»å‹", "ä¸šåŠ¡ç±»å‹_å¤§ç±»": "è®¢å•ç±»å‹"}
    )
else:
    df_diff = pd.DataFrame(columns=["è®¢å•æ¦‚è¿°", "ç»“æ„åŒ–ä¸šåŠ¡ç±»å‹", "è®¢å•ç±»å‹"])
report_tables["ä¸šåŠ¡ç±»å‹å¯¹æ¯”"] = df_diff

# 12. æ˜ç»†å…¨è¡¨
report_tables["æ˜ç»†å…¨è¡¨"] = df

# â€”â€”â€” 4. è¾“å‡ºç¾åŒ–Excelï¼Œå¤šsheetè‡ªåŠ¨åˆ—å®½å’Œè¡¨æ ¼æ ·å¼ â€”â€”â€”
with pd.ExcelWriter(XLSX_OUT, engine="openpyxl", mode="w") as writer:
    for name, table in report_tables.items():
        table.to_excel(writer, index=False, sheet_name=name[:31])

def auto_adjust_column_width_and_style(xlsx_path: Path):
    wb = load_workbook(xlsx_path)
    for ws in wb.worksheets:
        for col in ws.columns:
            max_length = max(len(str(cell.value or "")) for cell in col)
            col_letter = get_column_letter(col[0].column)
            ws.column_dimensions[col_letter].width = max_length + 2
        if ws.title != "æ˜ç»†å…¨è¡¨":
            end_row = ws.max_row
            end_col = ws.max_column
            if end_row > 1 and end_col > 0:
                tab = Table(displayName=f"Table_{ws.title.replace(' ', '_')}",
                            ref=f"A1:{get_column_letter(end_col)}{end_row}")
                style = TableStyleInfo(name="TableStyleMedium9", showFirstColumn=False,
                                      showLastColumn=False, showRowStripes=True, showColumnStripes=False)
                tab.tableStyleInfo = style
                ws.add_table(tab)
    wb.save(xlsx_path)

auto_adjust_column_width_and_style(XLSX_OUT)
logging.info("âœ… æ‰€æœ‰ç»Ÿè®¡å®Œæˆï¼Œåˆ†æExcelå·²è¾“å‡ºåˆ°å¸æœºä¸šåŠ¡_ç»Ÿè®¡åˆ†æ.xlsxï¼")
